{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "261938eb558e7e1668193d05fbc44200",
     "grade": false,
     "grade_id": "cell-b54abdd2d53da94b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Decision Trees\n",
    "\n",
    "Decision trees are a supervised learning algorithm used for both classification and regression tasks. In this assignment we are going to take a look at applying them to classification, which is the task for which they were originally developed. One of the key properties of decision trees is that you can use them for problems where you have numerical and also categorical input features. The decision tree you will be making will be based on the *ID3* algorithm. After building our own *ID3* tree, we will then use scikit-learn to explore numerical decision trees and some possibilities for improving them.\n",
    "\n",
    "## Predicting heart disease \n",
    "\n",
    "The data set we will be using for this assignment contains heart disease diagnosis results from 4 different hospitals, and is included with the zip file. Take a look at the `heart-disease.names` file, which contains a description of the data set. The file also gives an explanation for the values of the different variables, so when our tree is complete we can interpret the decision rules created by the algorithm. \n",
    "\n",
    "Some variables included here, like *#9 cp: chest pain type*, with 4 labels for different types of chest pain, are clearly categorical. Then there are variables like *#12 chol: serum cholestoral in mg/dl*, containing the concentration of cholesterol, an obvious numeric value. The ability to handle both of these types of data is something not many other machine learning algorithms can do effectively, so in theory a decision tree should be perfect for this data.\n",
    "\n",
    "The cell below combines the 4 data files from different hospitals into a single data frame. It also cleans up the missing values by simply dropping any rows that contain missing values. Lastly, it separates out the target variable, i.e. the feature we're trying to predict with the decision tree, from the rest of the data set. Here the target variable is the actual diagnosis of heart disease, which is set to either `True` or `False` for each patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9861bbbe6cae0238084dd480966e3750",
     "grade": false,
     "grade_id": "cell-af61d7e5aa5c4695",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "28   56.0  1.0  4.0     120.0  100.0  0.0      0.0    120.0    1.0      1.5   \n",
       "405  47.0  1.0  4.0     150.0  226.0  0.0      0.0     98.0    1.0      1.5   \n",
       "617  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "618  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "619  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
       "914  57.0  0.0  4.0     140.0  241.0  0.0      0.0    123.0    1.0      0.2   \n",
       "915  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "916  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "917  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "918  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "\n",
       "     slope   ca  thal    num  \n",
       "28     2.0  0.0   7.0   True  \n",
       "405    2.0  0.0   7.0   True  \n",
       "617    3.0  0.0   6.0  False  \n",
       "618    2.0  3.0   3.0   True  \n",
       "619    2.0  2.0   7.0   True  \n",
       "..     ...  ...   ...    ...  \n",
       "914    2.0  0.0   7.0   True  \n",
       "915    2.0  0.0   7.0   True  \n",
       "916    2.0  2.0   7.0   True  \n",
       "917    2.0  1.0   7.0   True  \n",
       "918    2.0  1.0   3.0   True  \n",
       "\n",
       "[299 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_names = ['va', 'hungarian', 'switzerland', 'cleveland']\n",
    "column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang',\n",
    "                'oldpeak', 'slope', 'ca', 'thal', 'num']\n",
    "\n",
    "# Read in all the different data files into a list of DataFrames\n",
    "data_files = [pd.read_csv(f'data/processed.{fn}.data', header=None, names=column_names) for fn in file_names]\n",
    "\n",
    "# Combine all the DataFrames into a single DataFrame\n",
    "df = pd.concat(data_files, ignore_index=True)\n",
    "# Force conversion to numeric values\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "# Remove missing or unconverted values\n",
    "df = df.dropna()\n",
    "\n",
    "# Target variable is in the last column\n",
    "target_var = df.columns[-1]\n",
    "# Convert target values to True or False\n",
    "df[target_var] = df[target_var] > 0\n",
    "\n",
    "# Separate target from input features\n",
    "data = df.drop(target_var, axis=1)\n",
    "labels = df[target_var]\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa353fdf87a213e4e07def24dcb45a67",
     "grade": false,
     "grade_id": "cell-bd8cf09d95a99e90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Dividing the data\n",
    "\n",
    "As a last preprocessing step we'll do a couple of divisions of the data, starting with sklearn's `train_test_split()`, which will create a training and testing set, randomly divided *70/30* from the full data set.\n",
    "\n",
    "We will also need to divide the training data and test data into categorical and numerical features, as the basic ID3 algorithm only works with categorical features (which is what we'll start with). This could be done manually by taking a good look at the description file `heart-disease.names`, but it can also be done by counting the amount of unique values present for a feature. We could estimate that a categorical feature will probably have no more than 10 different unique categorical values, while it seems very likely that there are more than 10 different numerical values for a numerical feature in the data.\n",
    "\n",
    "Using this criterion, both the training and test data are further split into sets of categorical and numeric features. The categorical part of the training data is displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9fd4cb6b54e0a902223496af8d3a29b",
     "grade": false,
     "grade_id": "cell-adaacc0fb1c207b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>exang</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex  cp  fbs  restecg  exang  slope  ca  thal\n",
       "690    1   4    0        2      0      1   2     6\n",
       "827    0   3    0        0      0      1   0     3\n",
       "909    1   4    0        0      1      3   0     6\n",
       "804    1   2    0        0      1      2   3     6\n",
       "635    0   3    0        0      0      1   0     3\n",
       "..   ...  ..  ...      ...    ...    ...  ..   ...\n",
       "772    1   4    0        2      0      2   3     3\n",
       "739    1   3    0        0      1      2   0     3\n",
       "630    1   2    0        0      0      1   0     7\n",
       "741    1   1    1        2      0      2   1     3\n",
       "884    1   3    1        0      0      2   1     6\n",
       "\n",
       "[209 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.3, random_state=10)\n",
    "\n",
    "# Set the threshold for the maximum numberof values for a categorical feature\n",
    "cat_threshold = 10\n",
    "# Create a mask for all data columns with categorical values according to the threshold\n",
    "cat_features = [len(np.unique(data[col])) < cat_threshold for col in data.columns]\n",
    "# Reverse the mask to get all numerical columns\n",
    "num_features = np.logical_not(cat_features)\n",
    "\n",
    "# Select categorical features and convert to ints\n",
    "train_data_cat = train_data.loc[:, cat_features].astype(int)\n",
    "# Select numerical features and convert to floats\n",
    "train_data_num = train_data.loc[:, num_features].astype(float)\n",
    "\n",
    "test_data_cat = test_data.loc[:, cat_features].astype(int)\n",
    "test_data_num = test_data.loc[:, num_features].astype(float)\n",
    "\n",
    "display(train_data_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1032e2b0d583fab5c901df6062ac577d",
     "grade": false,
     "grade_id": "cell-1b6cf3b6a79a6f1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Assignment 1: Entropy\n",
    "\n",
    "There are quite a few different definitions of what entropy is; all of them relate to the notion of chaos / order in a system, but the exact definition strongly depends on the context in which the term is used. Most commonly the term refers to thermodynamic entropy, where it describes the number of possible configurations a thermodynamic system can have in a specific state. This is related to the idea of a universal entropy, as used in Asimov's classic short story [The Last Question](http://multivax.com/last_question.html). For decision trees we need the information theoretic entropy, or Shannon entropy, which says something about the amount of information contained in a distribution of data. The more ordered or one-sided the distribution is, the less bits we would need on average to express the exact distribution.\n",
    "\n",
    "We will use this measure of entropy to compare the results of decision tree splits to see which is the \"most informative\". For the heart disease problem there are now only 2 class labels we are considering, `True` if the patient has a heart disease diagnosis and `False` otherwise. For a 2 class problem, the entropy is defined as:\n",
    "\n",
    "$$\\phi(p) = −p\\ log_2(p) − (1 − p)\\ log_2(1 − p)$$\n",
    "\n",
    "where $p$ is the ratio between the labels for class 1 and class 2. \n",
    "\n",
    "First, write a `ratio` function to compute $p$. The function should, given a list of boolean values as class labels, return the ratio of `True` labels in the list, e.g.\n",
    "\n",
    "* A ratio of $1.0$ would indicate the list only contained `True`,\n",
    "* a ratio of $0.0$ would mean there were only `False` labels,\n",
    "* and $0.5$ would be a half `True` and half `False`.\n",
    "\n",
    "Next, using this `ratio` function to compute $p$, we can compute the actual entropy. However, there is one case that is a little tricky; when $p=0$, meaning there are no labels are `True`, actually computing the value $log_2(0)$ would then (correctly) result in a math error. Luckily, the whole term  $-0\\ log_2(0)$, can also just be defined as having the value $0$ (as it is multiplied by $0$).\n",
    "\n",
    "Write the function `entropy_sub` to compute the value of the log product ($-p\\ log_2(p)$), making sure to return $0$ in the case that $p = 0$. Finally, combine the functions `ratio` and `entropy_sub` to compute the `entropy` $\\phi$ of a list of boolean class labels. Try to reuse the same `entropy_sub` function for *both* halves of the entropy equation, so your code doesn't produce an error for the second half, in the case $p = 1$, either.\n",
    "\n",
    "If your functions are correct, the plot below should look familiar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "779e33d66011a973142b04b76931c342",
     "grade": true,
     "grade_id": "cell-2a9b5a326e02b49d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ratio(labels):\n",
    "    '''\n",
    "    function computes ratio: the number of True booleans in a list / length of list.\n",
    "    '''\n",
    "\n",
    "    p = sum(labels) / len(labels)\n",
    "    \n",
    "    return p\n",
    "\n",
    "def entropy_sub(p):\n",
    "    '''\n",
    "    function computes two parts of the entropy formula and returns these parts seperately.\n",
    "    '''\n",
    "    \n",
    "    # return  0  in the case that p = 0\n",
    "    if p == 0:\n",
    "        sub1 = 0\n",
    "        sub2 = 0\n",
    "    \n",
    "    # return  1  in the case that p = 1\n",
    "    elif p == 1:\n",
    "        sub1 = 0\n",
    "        sub2 = 0\n",
    "        \n",
    "    # compute log_product in other cases\n",
    "    else:\n",
    "        log_part = np.log2(p)\n",
    "        sub1 = -p * log_part\n",
    "        \n",
    "        # compute other part of entropy\n",
    "        log_part = np.log2((1-p))\n",
    "        sub2 = (1-p) * log_part\n",
    "    \n",
    "    \n",
    "    return sub1, sub2\n",
    "    \n",
    "\n",
    "def entropy(labels):\n",
    "    \n",
    "    # compute p\n",
    "    p = ratio(labels)\n",
    "    \n",
    "    # compute entropy_sub\n",
    "    sub1, sub2 = entropy_sub(p)\n",
    "    \n",
    "    # compute entropy\n",
    "    entropy = sub1 - sub2\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "# construct 50 different lists of labels\n",
    "N = 50\n",
    "\n",
    "# compute the ratio and entropy for each list\n",
    "ratios, entropies = [], []\n",
    "for i in range(N+1):\n",
    "    \n",
    "    # Add `i` times True and `N-i` times False to the list\n",
    "    label_list = i*[True] + (N-i)*[False]\n",
    "    \n",
    "    # Compute the ratio for that list\n",
    "    ratios.append(ratio(label_list))\n",
    "    \n",
    "    # Compute the entropy for that list\n",
    "    entropies.append(entropy(label_list))\n",
    "\n",
    "plt.plot(ratios, entropies)\n",
    "plt.xlabel(\"$p$ (ratio)\")\n",
    "plt.ylabel(\"$\\phi$ (entropy)\")\n",
    "\n",
    "plt.title(\"Shannon entropy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1c11fe1c02cd5f1dfc08c6189d12cf5",
     "grade": false,
     "grade_id": "cell-0dee244b81322e29",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Assignment 2: Splitting data\n",
    "\n",
    "Next, we'll work on some of the functions to actually create the data set splits. **A split is a grouping of samples in a data set by each of the unique values for _one_ of the features.**\n",
    "\n",
    "As an example, let's say we have the following small sample data set for the PlayTennis problem:\n",
    "\n",
    "<br><img src=\"src/tennis.png\" width=\"45%\"><br>\n",
    "\n",
    "Here there are 4 features, *Outlook*, *Temperature*, *Humidity* and *Wind*, recorded for each *Day*. The target label we're trying to predict is whether or not it is a good day to *PlayTennis*.\n",
    "\n",
    "Let's start by separating out the label from the other features:\n",
    "\n",
    "<br><img src=\"src/tennis_labels.png\" width=\"80%\"><br>\n",
    "\n",
    "There are 4 possible features to split the data set on. The result of a split should be a **dictionary**, where each key is the feature value being split on, and the value is the corresponding subset of the data or the labels.\n",
    "\n",
    "Let's say we split on the feature *Outlook* first, the resulting split would then look as follows:\n",
    "\n",
    "<br><img src=\"src/outlook_split.png\" width=\"80%\"><br>\n",
    "\n",
    "As an intermediate step, before creating the actual split dictionaries, you should create a dictionary containing boolean masks to select each of these subsets. These masks can then be applied to create the splits of both the data and the labels.\n",
    "\n",
    "For the example split above, this would then be that intermediate masking dictionary:\n",
    "\n",
    "<br><img src=\"src/outlook_mask.png\" width=\"80%\"><br>\n",
    "\n",
    "First, write the function `masks_for_split`, which takes a `dataframe` and the name of the `feature` for which to create the split. The function should return a dictionary with each of the unique values of the feature as keys, and the corresponding boolean masks as values. The example above should be the result of calling \n",
    "\n",
    "    outlook_mask = masks_for_split(tennis_data, 'Outlook')\n",
    "    \n",
    "You can use [np.unique](https://numpy.org/doc/stable/reference/generated/numpy.unique.html) to find all the unique values for that feature. Creating a boolean mask array is described [here](https://numpy.org/doc/stable/user/basics.indexing.html#boolean-or-mask-index-arrays).\n",
    "\n",
    "Next, write the function `apply_split`, which takes a `dataframe` and a dictionary of `split_masks`. The function should apply each mask to the dataframe and return the resulting split dictionary. For the example above, the call creating the split would be\n",
    "\n",
    "    outlook_split_data = apply_split(tennis_data, outlook_mask)\n",
    "    outlook_split_labels = apply_split(tennis_labels, outlook_mask)\n",
    " \n",
    "Use the provided tennis data below to test whether both your functions work correctly, as this will be a lot easier to do the verification with than the full heart disease data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f03469901e112a4a046e96036966c04",
     "grade": true,
     "grade_id": "cell-70629a51ec62dcd9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D1</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D4</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D5</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D6</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Outlook Temperature Humidity    Wind\n",
       "D1     Sunny         Hot     High    Weak\n",
       "D2     Sunny         Hot     High  Strong\n",
       "D3  Overcast         Hot     High    Weak\n",
       "D4      Rain        Mild     High    Weak\n",
       "D5      Rain        Cool   Normal    Weak\n",
       "D6      Rain        Cool   Normal  Strong"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlayTennis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D4</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D5</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D6</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PlayTennis\n",
       "D1       False\n",
       "D2       False\n",
       "D3        True\n",
       "D4        True\n",
       "D5        True\n",
       "D6       False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def masks_for_split(dataframe, feature):\n",
    "    '''\n",
    "    function creates a dictionary with each of the unique values of the feature as keys, \n",
    "    and the corresponding boolean masks as values. \n",
    "    '''\n",
    "   \n",
    "    # get unique features in column\n",
    "    unique_values = np.unique(dataframe[feature])\n",
    "    \n",
    "    # place features in dictionary as keys\n",
    "    split_masks = {}\n",
    "    for unique_value in unique_values:\n",
    "        mask = dataframe[feature] == unique_value\n",
    "        split_masks[unique_value] = mask\n",
    "    \n",
    "    return split_masks\n",
    "    \n",
    "\n",
    "def apply_split(dataframe, split_masks):\n",
    "    '''\n",
    "    function takes a dataframe and a dictionary of split_masks. \n",
    "    The function should apply each mask to the dataframe and return the resulting split dictionary\n",
    "    '''\n",
    "    \n",
    "    # declare empty dict to fill in\n",
    "    split_dict = {}\n",
    "    \n",
    "    # look for specific feature\n",
    "    for feature in split_masks:\n",
    "        \n",
    "        # create mask for specific feature, apply to dataframe and store in dict\n",
    "        mask = list(split_masks[feature])\n",
    "        split_dict[feature] = dataframe[mask]\n",
    "    \n",
    "    return split_dict\n",
    "\n",
    "\n",
    "tennis_data = pd.DataFrame([\n",
    "    ['Sunny', 'Hot', 'High', 'Weak'], ['Sunny', 'Hot', 'High', 'Strong'], ['Overcast', 'Hot', 'High', 'Weak'],\n",
    "    ['Rain', 'Mild', 'High', 'Weak'], ['Rain', 'Cool' ,'Normal', 'Weak'], ['Rain', 'Cool', 'Normal', 'Strong']],\n",
    "    index=['D1', 'D2', 'D3', 'D4', 'D5', 'D6'], columns = ['Outlook', 'Temperature', 'Humidity', 'Wind'])\n",
    "\n",
    "tennis_labels = pd.DataFrame([\n",
    "    [False], [False], [True], [True], [True], [False]],\n",
    "    index=['D1', 'D2', 'D3', 'D4', 'D5', 'D6'], columns = ['PlayTennis'])\n",
    "\n",
    "display(tennis_data)\n",
    "display(tennis_labels)\n",
    "\n",
    "outlook_mask = masks_for_split(tennis_data, \"Outlook\")\n",
    "outlook_split_data = apply_split(tennis_data, outlook_mask)\n",
    "outlook_split_labels = apply_split(tennis_labels, outlook_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e53c8c28091172af53431c65b50ce917",
     "grade": false,
     "grade_id": "cell-62d0650f7dda5669",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Assignment 3: Information gain\n",
    "\n",
    "Information Gain measures how much the entropy changes from making a specific split, i.e. the gain in predictability of the data as a result of making a distribution based on a specific feature. When a set of target labels $S$ is split on a feature (or attribute) $A$, two or more new lists are created, each with their own entropy. Combining the resulting entropies from a split into new subsets $S_v$ is done as a weighted sum. The Information Gain is the difference between the old entropy of $S$ and the weighted sum of the new entropies resulting from the split on attribute $A$:\n",
    "\n",
    "$$IG(S, A) = \\phi(S) - \\sum_{v \\in Values(A)} \\frac{|S_v|}{|S|} \\phi(S_v) $$\n",
    "\n",
    "Here $S$ is the set of target labels and $S_v$ is the subset of $S$ where the value of the attribute $A$ is equal to $v$. $|S|$ and $|S_v|$ are the size of the original label set and the subset respectively. Therefore, $|S|$ is always equal to the number of samples before the split (as each sample has exactly one label) and $|S_v|$ is equal to the size of the subset of data where the value of the attribute $A$ is equal to $v$.\n",
    "\n",
    "Continuing the tennis example from before, in order to compute the information gain of splitting the data on *Outlook*, we'll need to look at what effect the split has on the labels we're trying to predict. For the split on *Outlook*, this would look like:\n",
    "\n",
    "<br><img src=\"src/outlook_split_labels.png\" width=\"80%\"><br>\n",
    "\n",
    "Each of the values of the dictionary here corresponds with one subset $S_v$, so $S_{sunny}$, $S_{overcast}$, and $S_{rain}$ respectively. The full set $S$ is just the union of these 3 subsets together.\n",
    "\n",
    "Constructing this dictionary with the split labels can be simply done by applying the split mask to the labels, as before: \n",
    "\n",
    "    outlook_split_labels = apply_split(tennis_labels, outlook_mask)\n",
    "\n",
    "Next, write a function `information_gain()`, which should implement $IG(S, A)$ and reuse your `entropy()` function from before to do so. The function argument `split_labels` is a dictionary with each of the split labels, like the `outlook_split_labels` example above. More precisely, `split_labels` is a dictionary with attribute values $v$ as the keys, mapping to the subset of labels $S_v$, corresponding to the samples that contain that value $v$.\n",
    "\n",
    "*Hint:* You can use [pd.concat](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) to \"glue\" the different subsets together in order to reconstruct $S$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "322e37a5345ddf33d988ffde84d6f02d",
     "grade": true,
     "grade_id": "cell-9f155dda2eac19e1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def information_gain(split_labels):\n",
    "    '''\n",
    "    function implements  𝐼𝐺(𝑆,𝐴),  using the entropy() function from before.\n",
    "    input is is a dictionary with attribute values  𝑣  as the keys, \n",
    "    mapping to the subset of labels  𝑆𝑣 , corresponding to the samples that contain that value  𝑣.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # create a list of seperate values and concatenate the dfs for every value\n",
    "    list_values = split_labels.values()\n",
    "    original_df = pd.concat(list_values, ignore_index = True)\n",
    "    \n",
    "    # calculate original entropy\n",
    "    original_entropy = entropy(original_df)\n",
    "    \n",
    "    # set IG to original entropy (S)\n",
    "    IG = original_entropy\n",
    "    \n",
    "    # calculate entropy for every label and update IG\n",
    "    for label in split_labels:\n",
    "        sub_entropy = entropy(split_labels[label])\n",
    "        IG -= (len(split_labels[label]) / len(original_df)) * sub_entropy\n",
    "        \n",
    "    return IG\n",
    "        \n",
    "IG = information_gain(apply_split(labels, masks_for_split(data, 'thal')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e725a3345ba1f93d245bd52f9dbe73fd",
     "grade": true,
     "grade_id": "cell-2985b88f0aa7290c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert abs(information_gain(apply_split(labels, masks_for_split(data, 'thal'))) \n",
    "           - 0.2136994692625539) < 1e-10, \"Information Gain for 'thal' is incorrect\" \n",
    "assert abs(information_gain(apply_split(labels, masks_for_split(data, 'ca'))) \n",
    "           - 0.1779347528954177) < 1e-10, \"Information Gain for 'ca' is incorrect\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef08367fb8457583ff016fd3632345cb",
     "grade": false,
     "grade_id": "cell-19f8f971af968b5e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Assignment 4: ID3\n",
    "\n",
    "Below is the code to create a complete DecisionTree object using the *ID3* algorithm. A part of the code has already been provided and documented. Start by reading the `__init__()` function to learn all the relevant variables that are stored for this class.\n",
    "\n",
    "Write the function `determine_best_split()`, which should consider all possible splits of the data, making use of the `masks_for_split()`, `apply_split()` and `information_gain()`, and find the best split. This function should update `self.info_gain`, `self.split_feature`, `self.split_data` and `self.split_labels` according to that best split, i.e. the split that provided the largest information gain.\n",
    "\n",
    "Next, complete the function `create_subtrees()`. Most of this function has already been written; you'll only need to add two more lines to complete the function. Even if it is quite a small function, it isn't trivial, and is one of the most important steps of the algorithm. Each subset of the data from the split is actually used to create another `DecisionTree`, which can then be split further again. Each of these subtrees are stored in `self.branches`, where the key is the attribute value for that part of the split and the value is the new decision subtree. This repeated step is what actually builds a complex decision tree, using the split results to create a new tree with another split, and so on. Start by reading the code that has already been given, and make sure that you understand it, before adding the remaining two lines. \n",
    "\n",
    "With these functions in place, the decision tree will actually already completely build itself! All that is now left to do, is to make sure this tree can also classify new samples. These new samples will always be a single row from a DataFrame, which is called a Series, with the same structure as the training data. Complete the function `classify()`, which should return the predicted class label, so either True or False, given a new sample. Again, there are only two lines you'll need to add here, but this short function is still complicated enough. The basic case for this function is to return the most common class label if this node is a leaf node or if the value of the feature that was split on does not occur in the branches. Otherwise, the decision tree will look up the subtree in the branch corresponding to the value of the feature that it was split on, and return the classification predicted by that subtree.\n",
    "\n",
    "Lastly, write the `validate()` function, which should take a dataframe `test_data` and classify every row in the DataFrame. The function should return the accuracy (i.e. percentage correct) of these classifications as compared to the actual class label contained in `test_labels`. For the heart disease data set, this decision tree with the default threshold of $0.1$ should have about *93%* accuracy on the training data and *82%* on the testing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec4b2c10d7e7590a4b35e610ecf7c6a7",
     "grade": true,
     "grade_id": "cell-f63726ddf48a61f0",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 93.77990430622009\n",
      "Test accuracy: 82.22222222222221\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class DecisionTree(object):\n",
    "    '''\n",
    "    class used to to create a complete DecisionTree object using the ID3 algorithm. \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, data, labels, thres=0.1):\n",
    "        '''\n",
    "        all the relevant variables that are stored for this class.\n",
    "        '''\n",
    "        \n",
    "        # The dataframe containing the samples belonging to this node\n",
    "        self.data = data\n",
    "        \n",
    "        # The corresponding class labels for each of these same samples\n",
    "        self.labels = labels\n",
    "        \n",
    "        # The minimum information gain for a split, below this stop splitting the tree\n",
    "        self.thres = thres\n",
    "        \n",
    "        \n",
    "        # These next 4 variables will be set by calling determine_best_split()\n",
    "        \n",
    "        # The information gain of the split at this node in the decision tree\n",
    "        self.info_gain = 0\n",
    "        \n",
    "        # The feature / attribute that this node was split on\n",
    "        self.split_feature = None\n",
    "        \n",
    "        # The dictionary containing the data split on the values of that feature\n",
    "        self.split_data = None\n",
    "        \n",
    "        # The dictionary containing the labels split on the values of that feature\n",
    "        self.split_labels = None\n",
    "        \n",
    "        # Find the best feature to split on and set the 4 variables above correctly\n",
    "        self.determine_best_split()\n",
    "    \n",
    "    \n",
    "        # Indicates if the current node is a leaf node, i.e. has no further splits\n",
    "        self.leaf = self.info_gain < self.thres\n",
    "        \n",
    "        # Assign this node the most common class label, either True or False\n",
    "        self.common_label = ratio(labels) >= 0.5\n",
    "    \n",
    "        # Dictionary containing the actual branches of the Decision Tree, where \n",
    "        # the keys are different values of the feature that was split on and\n",
    "        # the values are new subtrees, created with data subsets from the split\n",
    "        self.branches = {}\n",
    "        \n",
    "        # Fill the branches of the decision tree by recursively creating subtrees\n",
    "        self.create_subtrees()\n",
    "        \n",
    "    def determine_best_split(self):\n",
    "        '''\n",
    "        function considers all possible splits of the data, making use of the masks_for_split(), \n",
    "        apply_split() and information_gain(), and find the best split. function updates\n",
    "        self.info_gain, self.split_feature, self.split_data and self.split_labels according to that best split.\n",
    "        '''\n",
    "        \n",
    "        for feature in self.data:\n",
    "            \n",
    "            # calculate IG\n",
    "            data_mask = masks_for_split(self.data, feature)\n",
    "            split_labels = apply_split(self.labels, data_mask)\n",
    "            IG = information_gain(split_labels)\n",
    "            \n",
    "            # update if appropriate:\n",
    "            if IG > self.info_gain:\n",
    "                \n",
    "                # update the feature / attribute that this node was split on\n",
    "                self.split_feature = feature\n",
    "                \n",
    "                # update the dictionary containing the data split on the values of that feature\n",
    "                self.split_data = apply_split(self.data, data_mask)\n",
    "\n",
    "                # update the dictionary containing the labels split on the values of that feature\n",
    "                self.split_labels = split_labels\n",
    "                \n",
    "                # update info gain\n",
    "                self.info_gain = IG\n",
    "\n",
    "              \n",
    "    def create_subtrees(self):\n",
    "        '''\n",
    "        function creates subtrees\n",
    "        '''\n",
    "        \n",
    "        # If the current node is not a leaf node, continue to split the data\n",
    "        if not self.leaf:\n",
    "            \n",
    "            # Loop through all the different possible values of the best split feature\n",
    "            for feature_value in self.split_data:\n",
    "                \n",
    "                # Retrieve the subset of the data that has this specific feature value\n",
    "                subset_data = self.split_data[feature_value]\n",
    "                \n",
    "                # Get the corresponding subset of the labels for that same feature value\n",
    "                subset_labels = self.split_labels[feature_value]\n",
    "\n",
    "                # This creates a new DecisionTree for each branch in the current tree. These new subtrees\n",
    "                # are created using the subsets of data and labels from the current split. Repeatedly \n",
    "                # constructing the subtrees in this ways, the data is split further and further each tree.\n",
    "                subtree = DecisionTree(subset_data, subset_labels, self.thres)\n",
    "                \n",
    "                # Each subtree is stored in the branches dictionary, using the split feature value as the\n",
    "                # key, so we can always find back the relevant branch for a sample. Each stored subtree\n",
    "                # can again contain subtrees in its owns branches, and so on, building the tree stucture.\n",
    "                self.branches[feature_value] = subtree\n",
    "                \n",
    "            \n",
    "    def classify(self, row):\n",
    "        '''\n",
    "        function returns the predicted class label, either True or False, given a new sample. \n",
    "        '''\n",
    "        \n",
    "        # If the current tree is a leaf, just return the most common label\n",
    "        if self.leaf:\n",
    "            return self.common_label\n",
    "        \n",
    "        # To classify a row from the DataFrame (i.e. a single sample), use the feature that this specific\n",
    "        # tree was split on and get the corresponding value of that feature from the row / sample.\n",
    "        split_feature_value = row[self.split_feature]\n",
    "        \n",
    "        # If that feature value is not one of the branches in this tree, just treat it as a leaf node\n",
    "        if split_feature_value not in self.branches:\n",
    "            return self.common_label\n",
    "        \n",
    "        # Else, get the relevant subtree from the branch belonging to the feature value from the row\n",
    "        # we are currently trying to classify (for the feature on which this specific tree was split).\n",
    "        subtree = self.branches[split_feature_value]\n",
    "        \n",
    "        # Use this subtree, which itself is a DecisionTree instance, to further determine the classification\n",
    "        # for this sample row, by calling the same function again on the subtree instance and returning its\n",
    "        # classification for the row.\n",
    "        return subtree.classify(row)\n",
    "        \n",
    "    \n",
    "    def validate(self, test_data, test_labels):\n",
    "        '''\n",
    "        function calls on classify function to classify every row in the DataFrame. \n",
    "        The function returns the accuracy (i.e. percentage correct) of these classifications\n",
    "        as compared to the actual class label contained in test_labels. \n",
    "        '''\n",
    "        \n",
    "        # set empty variables to calculate accuracy later\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # get test data classification (y_hat) and actual test labels (y)\n",
    "        for index, row in test_data.iterrows():\n",
    "            y_hat = self.classify(row)\n",
    "            y = test_labels[index]\n",
    "            \n",
    "            # update variables to calculate accuracy: compare to test_data and test_labels\n",
    "            if y_hat == y:\n",
    "                correct += 1\n",
    "            \n",
    "            # update total count\n",
    "            total += 1\n",
    "        \n",
    "        # calculate accuracy\n",
    "        accuracy = correct / total * 100\n",
    "        \n",
    "        return accuracy\n",
    "            \n",
    "        \n",
    "\n",
    "tree = DecisionTree(train_data_cat, train_labels)\n",
    "\n",
    "print(f'Train accuracy: {tree.validate(train_data, train_labels)}')\n",
    "print(f'Test accuracy: {tree.validate(test_data, test_labels)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36944f7384a60857e533cdd2d94b5a14",
     "grade": false,
     "grade_id": "cell-c465ec3ae9d29335",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Assignment 5: Numerical Decision Tree\n",
    "\n",
    "Now that our Categorical Decision Tree is done, we will take a look at a Numerical Decision tree. As described in the theory videos, it is possible to extend the Categorical Decision Tree to also include numerical boundaries. We could then use this to even select the best Information Gain from *both* the categorical *and* the numerical splits at each node.\n",
    "\n",
    "However, for now we will focus on a model that can *only* make numerical splits, as that is what the `scikit-learn` library provides straight out of the box: The [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) is a class that can build a decision tree from numerical data, and so we won't have to implement this tree from scratch.\n",
    "\n",
    "The most important difference between categorical and numerical decision trees is the way the data is split. In categorical data, it is easy to split the tree into the $N$ categories that are present in the data. This is impossible to do in numerical data, as there are infinitely many categories. Categorical Decision trees therefore use binary splits or a so-called split boundary; where with each split we create one branch with values smaller than the boundary, and one branch with values greater than or equal to the boundary.\n",
    "\n",
    "This boundary for a feature can be determined by trying every possible split boundary available for the set of values. This is done by first sorting the samples and then trying every split half way between two neighbouring values that have different labels. This means there can be as many splits as there are samples, and as such this method is computationally very expensive. An alternative, simpler method that is often used, is trying some amount of random splits for a feature and picking the best random split among them.\n",
    "\n",
    "Note that repeated binary splits on the same numerical variable can be used to create many different \"decision regions\" for the same variable. For example, consider a label where you want a variable to be above or equal to 3.4, but below 4.8. Here you would need two splits; a first split with 3.4 as the boundary and then in the \"greater equal branch\" of that split, another split boundary of 4.8 on that same variable. This means that while the feature that was split on could be ignored in further splits in the case of a Categorical Decision tree, this is not the case for Numerical Decision Trees, and repeated splits on the same variable can actually greatly improve accuracy.\n",
    "\n",
    "Implement a Numerical Tree Classifier using a `sklearn.tree.DecisionTreeClassifier` and its `fit` and `predict` functions. Train it using the numerical part of the dataset `train_data_num` that was separated out earlier (see the second code cell of this notebook) and print the training and test accuracies. Determining the accuracy can easily be done through the `metrics.accuracy_score` method from the `metrics` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65bfd7af254bfbae3e76e8b03dc5c629",
     "grade": true,
     "grade_id": "cell-4166de4116a6d6f4",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.6777777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# create tree\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# predictions for training data\n",
    "\n",
    "# fit the data\n",
    "clf = clf.fit(train_data_num, train_labels)\n",
    "\n",
    "# use model to predict class of samples\n",
    "predictions = clf.predict(train_data_num)\n",
    "\n",
    "# calculate metrics for training data \n",
    "accuracy_training = accuracy_score(train_labels, predictions)\n",
    "    \n",
    "# predictions for testing data\n",
    "\n",
    "# use model to predict class of samples\n",
    "predictions = clf.predict(test_data_num)\n",
    "\n",
    "# calculate metrics for ttesting data \n",
    "accuracy_testing = accuracy_score(test_labels, predictions)\n",
    "\n",
    "\n",
    "print(f'Train accuracy: {accuracy_training}')\n",
    "print(f'Test accuracy: {accuracy_testing}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "042db3fae02a545aa6ce4607c886f10e",
     "grade": false,
     "grade_id": "cell-3267e1c6b979d1ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The scikit-learn Decision Trees implementation is specifically intended for numerical features. This might not be immediately obvious, but if we read the documentation on [Decision Trees](https://scikit-learn.org/stable/modules/tree.html#tree-algorithms-id3-c4-5-c5-0-and-cart) and see what algorithms it uses, we find:\n",
    "\n",
    "```scikit-learn uses an optimised version of the CART algorithm; however, scikit-learn implementation does not support categorical variables for now.```\n",
    "\n",
    "Even if it does not actually support categorical data, you can *still* make this implementation work, provided that you give each category a number. **Note: This is not recommended (discouraged even), as this suggests that there is an ordering (the numerical order) to the categorical data.** For many models, saying category 1 is before category 3, and category 2 is somewhere in between them, can really screw up your predictions.\n",
    "\n",
    "Even though this is not recommended, since our data already has integer numbers for each of the categories we could easily try and see what works. Train a Numerical Tree Classifier using `sklearn.DecisionTreeClassifier` and the categorical data `train_data_cat`, and print the training and test accuracies. Next, train using the complete training data `train_data`, i.e. categorical and numerical combined and also report the training and testing accuracies.\n",
    "\n",
    "*Note: the linked page on Decision Trees contains more useful information and hints if you plan to use this model on any projects of your own, so it might be worth reading through.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fa4b99b550aecb3cd7f6c8c460e0a89",
     "grade": true,
     "grade_id": "cell-ea8f0840b30026d8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9521531100478469\n",
      "Test accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# TRAIN USING THE CATEGORICAL DATA\n",
    "\n",
    "# create tree\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# predictions for training data\n",
    "\n",
    "# fit the data\n",
    "clf = clf.fit(train_data_cat, train_labels)\n",
    "\n",
    "# use model to predict class of samples\n",
    "predictions = clf.predict(train_data_cat)\n",
    "\n",
    "# calculate metrics for training data \n",
    "accuracy_training = accuracy_score(train_labels, predictions)\n",
    "\n",
    "    \n",
    "# predictions for testing data\n",
    "\n",
    "# use model to predict class of samples\n",
    "predictions = clf.predict(test_data_cat)\n",
    "\n",
    "# calculate metrics for testing data \n",
    "accuracy_testing = accuracy_score(test_labels, predictions)\n",
    "\n",
    "print(f'Train accuracy: {accuracy_training}')\n",
    "print(f'Test accuracy: {accuracy_testing}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "# TRAIN USING THE COMPLETE DATA\n",
    "\n",
    "# create tree\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# predictions for training data\n",
    "\n",
    "# fit the data\n",
    "clf = clf.fit(train_data, train_labels)\n",
    "\n",
    "# use model to predict class of samples\n",
    "predictions = clf.predict(train_data)\n",
    "\n",
    "# calculate metrics for training data \n",
    "accuracy_training = accuracy_score(train_labels, predictions)\n",
    "    \n",
    "# predictions for testing data\n",
    "\n",
    "# use model to predict class of samples\n",
    "predictions = clf.predict(test_data)\n",
    "\n",
    "# calculate metrics for testing data \n",
    "accuracy_testing = accuracy_score(test_labels, predictions)\n",
    "\n",
    "print(f'Train accuracy: {accuracy_training}')\n",
    "print(f'Test accuracy: {accuracy_testing}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis questions \n",
    "\n",
    "Answer these questions about the results. Write your answers below each question in this cell.\n",
    "\n",
    "**Q1. Why does the training accuracy for numerical splits become 1.0 (i.e. a perfect fit), but remains lower for categorical splits?**\n",
    "\n",
    "*The numerical split is overfitting. The categorical is not, because the samples can have overlapping features which would cancel each other out which prevents overfitting.*\n",
    "\n",
    "**Q2. Explain how it is possible that in some cases the testing accuracy using only the categorical variables can be higher than the testing accuracy using the categorical and numeric variables combined. What property of the Decision Tree causes this?**\n",
    "\n",
    "*The use of numerical features leads to overfitting so if you use both types, you are more likely to overfit due to the use of those numerical featues. This decreases the accuracy. The property of DTC that causes this is that the implementation will continue separating nodes until they are either pure or no more conditions can be set to further improve purity.*\n",
    "\n",
    "**Q3. While using categorical data as if it is numerical is generally not recommended, in Decision Trees it doesn't seem as problematic. In fact, we could always reproduce a discrete split using a combination of numeric splits on that same variable. Explain how many splits we would need and what the structure might look like.**\n",
    "\n",
    "*You'd need n-1 splits. In that case, the structure would look something like: a node structure that starts with one node and creates two seperate nodes in the next layer that contain half of the categorical data left. e.g. For 4 categorical features:\n",
    "\n",
    "\n",
    "                                    n\n",
    "                                   / \\\n",
    "                                  n    n\n",
    "                                 /\\    /\\\n",
    "                                n  n  n  n\n",
    "*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae266ab9ca2f1d8bb3aa3fe00215b81b",
     "grade": false,
     "grade_id": "cell-87be1ef48ee25fac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Assignment 6: Preventing overfitting\n",
    "\n",
    "As we now know, trees learn by beginning with the full training set and greedily adding conditions that maximize each child nodes' label purity. As the tree grows, each node adds another condition resulting in smaller subgroups. In fact, the number of leaf-nodes grows exponentially as we add more depth to the tree and in just a few splits a training set with thousands of examples can be reduced to a set of leaves with sizes around 1-20, which lack statistical validity. Since our implementation will continue separating nodes until they are either pure or no more conditions can be set to further improve purity, it is very probable that we force our tree to overfit.\n",
    "\n",
    "There are several techniques that deal with tree overfitting. It is possible to prune the tree, for example by removing leaves once the tree is complete, or by preventing it from growing as deep in the first place by setting a threshold on the minimum Information Gain.\n",
    "\n",
    "Scikit-learn's [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) has several argument options to help prevent overfitting. Probably the easiest to get started with is `min_samples_split`, which sets what the minimum number of samples in a node should be before it can be split. If a node has fewer samples than this number, it will not be split further and the predicted label just becomes the most common label at that node.\n",
    "\n",
    "Try several values for `min_samples_split` and give a value that definitely still overfits, a value that definitely causes underfitting and the value you think gives the best fit on the data. Report the training and testing accuracy for each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba163627f50a087ae2a82b669755eab2",
     "grade": true,
     "grade_id": "cell-2466ba53dc428536",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'minimum number of samples required')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRAIN USING THE CATEGORICAL DATA\n",
    "\n",
    "# create empty lists for plotting\n",
    "list_training = []\n",
    "list_testing = []\n",
    "\n",
    "# create list of possible min_samples_split values\n",
    "num_list = list(range(2, 100))\n",
    "\n",
    "for minimum_number in num_list:\n",
    "\n",
    "    # create tree\n",
    "    clf = DecisionTreeClassifier(min_samples_split = minimum_number)\n",
    "\n",
    "    # predictions for training data\n",
    "\n",
    "    # fit the data\n",
    "    clf = clf.fit(train_data_cat, train_labels)\n",
    "\n",
    "    # use model to predict class of samples\n",
    "    predictions = clf.predict(train_data_cat)\n",
    "\n",
    "    # calculate metrics for training data \n",
    "    accuracy_training = accuracy_score(train_labels, predictions)\n",
    "\n",
    "\n",
    "    # predictions for testing data\n",
    "\n",
    "    # use model to predict class of samples\n",
    "    predictions = clf.predict(test_data_cat)\n",
    "\n",
    "    # calculate metrics for testing data \n",
    "    accuracy_testing = accuracy_score(test_labels, predictions)\n",
    "    \n",
    "    list_training.append(accuracy_training)\n",
    "    list_testing.append(accuracy_testing)\n",
    "\n",
    "plt.plot(num_list, list_testing)\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"minimum number of samples required\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4. Which minimum split size gives the best fit on the data? Explain why you choose this value.**\n",
    "\n",
    "*The outcomes seem to change everytime that I run the cell. But the accuracy consistently seems to be the highest at around 15 based on the ranges that I tried between 2 and 100. Best minimum split size that gives the best fit on the testing data is probably 15. (the plot above is difficult to read but when I decrease the range from 2 to 30 the plot clearly indicates that the best split occurs at split size 15)\n",
    "\n",
    "I did not bother to check beyond 100 because the accuracy only seems to drop and it would only take up more time and make the data less readable.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e2dd44bba96d5a86d0128249a8b074a3",
     "grade": false,
     "grade_id": "cell-23464b2e9df15f71",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Assignment 7: Plotting the Decision Tree\n",
    "\n",
    "Sklearn also comes with a tool that can actually plot the whole decision tree. However, plotting the complete tree would be a bit hard to read, as it wouldn't really fit in the figure. We can again use another `DecisionTreeClassifier` argument to limit the size of the tree. Here using `max_depth` makes the most sense, as we want to uniformly cut the tree at a certain depth for the plot.\n",
    "\n",
    "Fit a decision tree of a limited depth and call it `d_tree`. The code below will already plot it. Make sure the tree is small enough so you can read off the values in the plot. If not, reduce the `max_depth` further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e48cdf526a352e5032114d6774948f4",
     "grade": true,
     "grade_id": "cell-c7ce4a1d14d7ad7f",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# create tree, max_depth to 3 for readability\n",
    "d_tree = DecisionTreeClassifier(min_samples_split = 13, max_depth = 3)\n",
    "\n",
    "# predictions for training data\n",
    "\n",
    "# fit the data\n",
    "d_tree = d_tree.fit(train_data, train_labels)\n",
    "\n",
    "# use model to predict class of samples\n",
    "predictions = d_tree.predict(train_data)\n",
    "\n",
    "# calculate metrics for training data \n",
    "accuracy_training = accuracy_score(train_labels, predictions)\n",
    "\n",
    "# predictions for testing data\n",
    "\n",
    "# use model to predict class of samples\n",
    "predictions = d_tree.predict(test_data)\n",
    "\n",
    "# calculate metrics for testing data \n",
    "accuracy_testing = accuracy_score(test_labels, predictions)\n",
    "\n",
    "figure(figsize=(15, 10))\n",
    "tree.plot_tree(d_tree, feature_names=df.columns.values,\n",
    "               class_names=['Healthy', 'Heart Disease'], impurity=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5. Try to read out the boundaries set in the decision tree. Refer back to the `heart-disease.names` if you don't know what a variable means. What parameters seem to be the best indicators for heart disease?**\n",
    "\n",
    "*Following the path of the decision tree, it seems that the best indicators for heart disease are: cp (chest pain), with oldpeak, with thalach.* Note that I used all the training data. so the outcome may have been different if I used only categorical or only numerical. \n",
    "\n",
    "**Q6. Explain why considering a very reduced version of the tree should still give some insight into the important factors of heart disease.**\n",
    "\n",
    "*Well, the decision tree splits first on the most important factors. So even with a reduced version, you can get some suggestion of what important factors are in relation to heart disease*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02435c89b28d735b8578d3e99275a5e2",
     "grade": false,
     "grade_id": "cell-901336bc1d8bea94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Assignment 8: Random Forests \n",
    "\n",
    "Another method for reducing overfitting is the ensemble approach. In an ensemble approach multiple models are trained on (variations of) the original dataset, and then used to give a combined prediction. A commonly used ensemble method for decision trees is Random Forest. The essence of Random Forest classification is to have many decision trees that have all been trained on a random subset of features with randomly drawn sample rows. These decision trees then all predict on unseen samples and a majority vote is used as the final prediction. This procedure usually leads to better model performance; while the predictions of a single tree are highly sensitive to noise in the training data; the average of many trees trained on very similar data is not.\n",
    "\n",
    "We will be implementing a simple but effective variant of Random Forest that creates a small sample of all training data and trains several of scikit's `DecisionTreeClassifier`s on a random subset of features. First, we will need to create the forest. Implement `create_forest` that should accept `n_trees`, the number of trees that should be in the forest, and returns a list containing all of the `DecisionTreeClassifier` objects. Check the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) for a way to change the maximum amount of features used in the tree to the square root of the number of features and use it when creating the classifiers. *This is an easy way to limit the number of features used in the classifier and will help to differentiate all the models learned by each of the trees.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3ac428bca1471ff25ce3a62ce952111",
     "grade": true,
     "grade_id": "cell-a6ebf59f25b4c4fb",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def create_forest(n_trees):\n",
    "    \n",
    "    # set empty list\n",
    "    forest = []\n",
    "    \n",
    "    # create opbject for all n trees\n",
    "    for i in range (n_trees):\n",
    "        _object = DecisionTreeClassifier(splitter = \"random\", max_features = \"sqrt\")\n",
    "        \n",
    "        # append to list\n",
    "        forest.append(_object)\n",
    "    \n",
    "    return forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49b1461dba02639579f182d7497d41f4",
     "grade": false,
     "grade_id": "cell-3d2632ba9e0d13d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now implement the function `train_forest` that accepts a `forest` (a list of `DecisionTreeClassifier` objects) and trains each of the trees with `ratio` samples from `data`. *Training each of the trees on different random subsets of the data will also help to differentiate all the models learned by each of the trees.*\n",
    "\n",
    "Hint: use the pandas [sample](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html) method to create your subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab5fd951c5b9fd84f9d6876ac938437e",
     "grade": true,
     "grade_id": "cell-537f446e4709ead8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_forest(forest, data, labels, ratio = 0.5):\n",
    "    \n",
    "    # set empty list for trees\n",
    "    model_trees = []\n",
    "    \n",
    "    for s_tree in forest:\n",
    "        \n",
    "        # create sample\n",
    "        sample = data.sample(frac = ratio)\n",
    "        \n",
    "        # fancy indexing to get labels (= get corresponding labels for each sample)\n",
    "        indeces = sample.index\n",
    "        label_indeces = labels[indeces]\n",
    "        \n",
    "        # fit the data\n",
    "        model_tree = s_tree.fit(sample, label_indeces)\n",
    "        \n",
    "        # add model_tree to list\n",
    "        model_trees.append(model_tree)\n",
    "\n",
    "    return model_trees\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3555fd997ecd7bd18c5e6da8a7cd7c25",
     "grade": false,
     "grade_id": "cell-81910ccd5da0e7d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Implement the function `predict_forest` that accepts a `forest` and predicts the target label for the passed `data`.\n",
    "\n",
    "Hint: since we only have two possible predictions, `True` and `False`, which are equal to 1 and 0 respectively, we can just add all predictions of all trees together, adding 1 or 0 for each. If we then divide the total prediction by the number of trees, we end up with an 'average vote' that can be rounded to be either 1 or 0; `True` or `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5cd91816621d2ae618bbcffe3fcfac9",
     "grade": true,
     "grade_id": "cell-f2e3979fbe0fecff",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def predict_forest(forest, data):\n",
    "\n",
    "    # set empty variable for sum predictions\n",
    "    predictions = 0\n",
    "    \n",
    "    for tree in forest:\n",
    "        \n",
    "        # use model to predict class of samples\n",
    "        prediction = tree.predict(data)\n",
    "        \n",
    "        # add value to total predictions\n",
    "        predictions += prediction\n",
    "        \n",
    "    # calculate average vote\n",
    "    average_vote = predictions / len(forest)\n",
    "    \n",
    "    # create mask for average votes\n",
    "    mask = average_vote >= 0.5\n",
    "    \n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9046e25c71504225fb5de581c728c81f",
     "grade": false,
     "grade_id": "cell-278bd7557ffe69db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, create a random forest with 1000 trees, each using only 3 or 4 random features ($\\approx \\sqrt{13}$) and train each forest with a 50% random sample of the complete training data. Print out the train and testing accuracy. Does this result improve over using just 1 tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82a6f03f41fe1a6c743a5c29a559792f",
     "grade": true,
     "grade_id": "cell-1639be235c230364",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.8555555555555555\n"
     ]
    }
   ],
   "source": [
    "#  create a random forest with 1000 trees\n",
    "n_trees = 1000\n",
    "n_features = 4\n",
    "forest = create_forest(n_trees)\n",
    "\n",
    "# train each forest with a 50% random sample of the complete training data\n",
    "model_trees = train_forest(forest, train_data, labels, ratio = 0.5)\n",
    "\n",
    "predicted_label_training = predict_forest(forest, train_data)\n",
    "\n",
    "# calculate metrics for training data \n",
    "accuracy_training = accuracy_score(train_labels, predicted_label_training)\n",
    "\n",
    "# gebruik zelfde forest voor predictions op test data\n",
    "predicted_label_testing = predict_forest(forest, test_data)\n",
    "    \n",
    "# Print out the train and testing accuracy\n",
    "\n",
    "# calculate metrics for testing data \n",
    "accuracy_testing = accuracy_score(test_labels, predicted_label_testing)\n",
    "\n",
    "print(f'Train accuracy: {accuracy_training}')\n",
    "print(f'Test accuracy: {accuracy_testing}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the test accuracy seems to be much higher! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
